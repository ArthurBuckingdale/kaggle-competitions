{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"dataset=pd.merge(pd.read_csv('/kaggle/input/ashrae-energy-prediction/weather_train.csv'),pd.merge(pd.read_csv('/kaggle/input/ashrae-energy-prediction/building_metadata.csv'),pd.read_csv('/kaggle/input/ashrae-energy-prediction/train.csv')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(dataset))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=dataset.iloc[1000000:13000000,0:15].values\ny_train=dataset.iloc[1000000:13000000,15].values\ndataset.sample(12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=np.delete(x_train,13,1)\nprint(x_train[400:410,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=np.delete(x_train,12,1)\nprint(x_train[400:410,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nlabelencoder_X_1 = LabelEncoder()\nx_train[:, 10] = labelencoder_X_1.fit_transform(x_train[:, 10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train[400:420,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from jdcal import gcal2jd, jd2gcal\nfor i in range(len(x_train)):\n    jd=[]\n    month=x_train[i,1][5:7]\n    day=x_train[i,1][8:10]\n    year=2000\n    hour=x_train[i,1][11:13]\n    ans=gcal2jd(year,int(month),int(day))\n    total=ans[0]+ans[1]\n    x_train[i,1]=total+(int(hour)/24)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train[30000:30010,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\nimp.fit(x_train)\nx_train_teset=imp.transform(x_train[:,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nx_train_teset = sc.fit_transform(x_train_teset)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the keras libraries\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Activation\n\n\nfrom tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n\n# Initialising the ANN\nclassifier = Sequential()\n#Adding the input layer and the first hidden layer\nclassifier.add(Dense(output_dim = 9 , kernel_initializer = 'uniform', activation = 'elu', input_dim = 13))\n#adding the second hidden layer\nclassifier.add(Dense(output_dim = 11 , init = 'uniform', activation = 'elu'))\nclassifier.add(Dense(output_dim = 11 , init = 'uniform', activation = 'elu'))\nclassifier.add(Dense(output_dim = 14 , init = 'uniform', activation = 'elu'))\nclassifier.add(Dense(output_dim = 11 , init = 'uniform', activation = 'elu'))\n#adding the output layer\nclassifier.add(Dense(output_dim = 1 , init = 'uniform', activation = 'elu'))\n#compiling the ANN\nclassifier.compile(optimizer = 'adam', loss = 'mean_squared_logarithmic_error', metrics = ['accuracy'] )\n\n#Fitting the ANN to the training set\nclassifier.fit(x_train_teset, y_train, batch_size=3000 , epochs = 50)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=200 , epochs = 10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=40000 , epochs = 50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=100000 , epochs = 50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=300 , epochs = 4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=20000 , epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=2000 , epochs = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=500000 , epochs = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit(x_train_teset, y_train, batch_size=5000 , epochs = 20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset=pd.DataFrame()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_teset=[]\ny_train=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_teset)\nx_train=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}